# -*- coding: utf-8 -*-
"""Modeling3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N__VZZRHLeaLsPNkuDws-_qTbZHIbMun

# Group 9 Term project
### 미국 구인공고 웹사이트 Glassdoor 직업 관련 데이터

목표:

산업별 또는 평점별 분포 분석, 급여 정규화 및 클러스터링, 회귀모델 등의 후속 분석을 통해 다음과 같은 결과를 얻고자 합니다.

-	기업의 규모, 업종, 소유 형태, 위치 등과 급여의 상관관계 분석
"""

# 라이브러리 import
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""# 1. 데이터 불러오기

[Data Science Jobs & Salaries 2024]
https://www.kaggle.com/datasets/fahadrehman07/data-science-jobs-and-salary-glassdoor?select=glassdoor_jobs.csv

### 데이터 셋 개요 (피처와 설명)
- Job Title	: 직책명
- Salary Estimate :	회사가 제공하는 직무에 대한 예상 급여
- Job Description	: 직무 설명
- Rating : 회사 평가
- Company Name : 회사명
- Location	: 작업 위치
- Headquarters	: 회사 본사
- Size	: 회사의 직원 수
- Founded	: 회사가 설립된 연도
- Type of ownership	: 민간, 공공, 정부 및 비영리 조직과 같은 소유권 유형
- Industry :	Aerospace, Energy 등 회사가 서비스를 제공하는 산업 유형
- Sector	: 산업(에너지), 부문(석유, 가스)와 같이 어떤 유형의 서비스를 제공하는지
- Revenue	: 회사의 총 수익
- Competitors	: 회사 경쟁사
"""

# 데이터 로드 및 'avg_salary' 결측치 제거
df = pd.read_csv("glassdoor_cleaned_final.csv")
df = df.dropna(subset=['avg_salary'])

"""# 2. 데이터 탐색 (EDA)"""

# 각 범주형 변수에 따른 평균 급여 출력
print(df.groupby('Size_cleaned')['avg_salary'].mean())
print(df.groupby('Ownership_Grouped')['avg_salary'].mean())
print(df.groupby('Industry')['avg_salary'].mean().sort_values(ascending=False).head(10))

# 수치형 변수 간의 상관관계 시각화
sns.heatmap(df[['Company_age', 'Rating', 'avg_salary']].corr(), annot=True)
plt.title("수치형 변수 간 상관관계")
plt.show()

# 기업 규모별 급여 분포 시각화
sns.boxplot(data=df, x='Size_cleaned', y='avg_salary')
plt.xticks(rotation=45)
plt.title("기업 규모별 급여 분포")
plt.show()

# 본사 위치에 따른 급여 분포 비교 (상위 10개 위치 기준)
top_states = df['Headquarters_state_binned'].value_counts().head(10).index
sns.boxplot(data=df[df['Headquarters_state_binned'].isin(top_states)],
            x='Headquarters_state_binned', y='avg_salary')
plt.xticks(rotation=45)
plt.title("본사 위치에 따른 급여 분포")
plt.show()

# 산업별 기업 나이와 급여의 관계 (다변량 시각화)
sns.lmplot(data=df, x='Company_age', y='avg_salary', hue='Sector', fit_reg=False)
plt.title("기업 연령과 급여 - 산업별 분포")
plt.show()

"""# 3. 기초 피처 엔지니어링
결측치 처리, 스케일링 및 인코딩
"""

# 분석에 사용할 feature 및 target 설정
features = ['Size_cleaned', 'Ownership_Grouped', 'Industry', 'Sector',
            'Location_state_binned', 'Headquarters_state_binned',
            'works_at_headquarters', 'Company_age', 'Rating']
target = 'avg_salary'

X = df[features]
y = df[target]

# 수치형, 범주형 변수 구분
numeric_features = ['Company_age', 'Rating']
categorical_features = list(set(features) - set(numeric_features))

# 수치형 변수 전처리: 결측치 평균 대체 후 표준화
num_imputer = SimpleImputer(strategy='mean')
num_scaler = StandardScaler()
X_num = num_scaler.fit_transform(num_imputer.fit_transform(X[numeric_features]))

# 범주형 변수 전처리: 결측치 최빈값 대체 후 one-hot 인코딩
cat_imputer = SimpleImputer(strategy='most_frequent')
X_cat_imputed = cat_imputer.fit_transform(X[categorical_features])
ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
X_cat = ohe.fit_transform(X_cat_imputed)

# 수치형 + 범주형 병합
from numpy import hstack
X_processed = hstack([X_num, X_cat])

"""# 4.  회기 모델 학습
- Random Forest
- Xgboost
- Gradient boosting

  회기모델 학습 및 평가 함수정의 (kfold corss validation :평가지표는 mae, mse,rscore활용)

"""

# 모델 성능 평가 함수 정의 (KFold 적용, MAE, MSE, RMSE, R2 계산)
def evaluate_model(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mae = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_absolute_error').mean()
    mse = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error').mean()
    rmse = np.sqrt(mse)
    r2 = cross_val_score(model, X, y, cv=kf, scoring='r2').mean()
    return mae, mse, rmse, r2

# 사용 모델 정의
models = {
    'RandomForest': RandomForestRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42, verbosity=0),
    'GradientBoosting': GradientBoostingRegressor(random_state=42)
}

# 각 모델에 대해 성능 평가
for name, model in models.items():
    mae, mse, rmse, r2 = evaluate_model(model, X_processed, y)
    print(f"{name} -> MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}")

"""# 5. 하이퍼 파라미터 튜닝
- girdsearch
- randomsearch
"""

# randomforest 하이퍼파라미터 튜닝 (GridSearchCV)
rfr = RandomForestRegressor(random_state=42)
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5],
}
gs = GridSearchCV(rfr, param_grid, cv=5, scoring='neg_mean_absolute_error')
gs.fit(X_processed, y)
print("Best RF Params:", gs.best_params_)

# XGBoost 하이퍼파라미터 튜닝 (RandomizedSearchCV)
xgb = XGBRegressor(random_state=42, verbosity=0)
rnd_params = {
    'n_estimators': [50, 100],
    'learning_rate': [0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7]
}
rs = RandomizedSearchCV(xgb, rnd_params, n_iter=5, cv=5, scoring='neg_mean_squared_error')
rs.fit(X_processed, y)
print("Best XGB Params:", rs.best_params_)

"""# 6. 상관관계 해석
특성 중요도 , 기업 특성(규모, 업종, 소유 형태, 위치 등)과 급여와의 연관성 시각화
"""

# 최적 하이퍼파라미터로 모델 학습 후 feature importance 확인
final_model = RandomForestRegressor(**gs.best_params_, random_state=42)
final_model.fit(X_processed, y)

# 특성 중요도 데이터프레임 생성
importances = final_model.feature_importances_
feature_names = numeric_features + list(ohe.get_feature_names_out(categorical_features))
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# 중요 변수 상위 15개 시각화
sns.barplot(data=importance_df.head(15), x='Importance', y='Feature')
plt.title("급여에 영향을 미치는 주요 기업 특성")
plt.show()
